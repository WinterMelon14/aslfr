{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10034663,"sourceType":"datasetVersion","datasetId":6180641}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\nimport h5py\nimport os\nimport math\nimport pyarrow.parquet as pq\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras import layers\nfrom rotary_embedding_tensorflow import apply_rotary_emb, RotaryEmbedding\n\nchar_to_idx = {\n    \"0\": 15,\n    \"1\": 16,\n    \"2\": 17,\n    \"3\": 18,\n    \"4\": 19,\n    \"5\": 20,\n    \"6\": 21,\n    \"7\": 22,\n    \"8\": 23,\n    \"9\": 24,\n    \" \": 0,\n    \"!\": 1,\n    \"#\": 2,\n    \"$\": 3,\n    \"%\": 4,\n    \"&\": 5,\n    \"'\": 6,\n    \"(\": 7,\n    \")\": 8,\n    \"*\": 9,\n    \"+\": 10,\n    \",\": 11,\n    \"-\": 12,\n    \".\": 13,\n    \"/\": 14,\n    \":\": 25,\n    \";\": 26,\n    \"=\": 27,\n    \"?\": 28,\n    \"@\": 29,\n    \"[\": 30,\n    \"_\": 31,\n    \"a\": 32,\n    \"b\": 33,\n    \"c\": 34,\n    \"d\": 35,\n    \"e\": 36,\n    \"f\": 37,\n    \"g\": 38,\n    \"h\": 39,\n    \"i\": 40,\n    \"j\": 41,\n    \"k\": 42,\n    \"l\": 43,\n    \"m\": 44,\n    \"n\": 45,\n    \"o\": 46,\n    \"p\": 47,\n    \"q\": 48,\n    \"r\": 49,\n    \"s\": 50,\n    \"t\": 51,\n    \"u\": 52,\n    \"v\": 53,\n    \"w\": 54,\n    \"x\": 55,\n    \"y\": 56,\n    \"z\": 57,\n    \"~\": 58,\n    \"<SOS>\": 60, # start of sequence\n    \"<EOS>\": 61, # end of sequence\n    \"<PAD>\": 59  # sequence padding token\n}\nLANDMARK_GROUPS = {\n    'face': list(range(0, 468)),\n    'left_hand': list(range(468, 489)),\n    'pose': list(range(489, 522)),\n    'right_hand': list(range(522, 543))\n}\nSOS_TOKEN = 60  # New class for Start of Sequence\nEOS_TOKEN = 61  # New class for End of Sequence\nPAD_TOKEN = 59\nNUM_CLASSES = 62 # Total number of classes including 3 special tokens\nTIME = 128 # How many frames are we cutting down to? Some sequences go to 300-600 frames, so if hardware allows, increase this\n# Get all physical devices (CPU and GPU)\ngpus = tf.config.list_physical_devices('GPU')\n# Enable GPU device only\nif gpus:\n    tf.config.set_visible_devices(gpus, 'GPU')  # Only use the first GPU\nprint(gpus)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-29T02:52:41.135262Z","iopub.execute_input":"2024-11-29T02:52:41.135630Z","iopub.status.idle":"2024-11-29T02:52:41.146255Z","shell.execute_reply.started":"2024-11-29T02:52:41.135592Z","shell.execute_reply":"2024-11-29T02:52:41.145352Z"}},"outputs":[{"name":"stdout","text":"[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"train_dataset = tf.data.Dataset.load(\"/kaggle/input/train-and-validation-datasets-use-tfsave/train_ds\")\nval_dataset = tf.data.Dataset.load(\"/kaggle/input/train-and-validation-datasets-use-tfsave/val_ds\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-29T02:52:41.148003Z","iopub.execute_input":"2024-11-29T02:52:41.148620Z","iopub.status.idle":"2024-11-29T02:52:41.200140Z","shell.execute_reply.started":"2024-11-29T02:52:41.148576Z","shell.execute_reply":"2024-11-29T02:52:41.199270Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"# Set max length for padding (adjust based on your data)\nmax_len = 64 # Including EOS and SOS\n# Add SOS, EOS, and PAD tokens to the labels\n# Set max length for padding (adjust based on your data)\n# Add SOS, EOS, and PAD tokens to the labels\n\nbatch_size = 64\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-29T02:52:41.201038Z","iopub.execute_input":"2024-11-29T02:52:41.201280Z","iopub.status.idle":"2024-11-29T02:52:41.205072Z","shell.execute_reply.started":"2024-11-29T02:52:41.201255Z","shell.execute_reply":"2024-11-29T02:52:41.204160Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"for sample_inputs, sample_outputs in train_dataset.take(1):\n    # Access the first few elements from the batch\n    print(\"Phrase (Decoder Inputs):\", sample_inputs[0])\n    print(\"Keypoints (Shape):\", sample_inputs.shape)\n    print(\"Decoder Outputs:\", sample_outputs[0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-29T02:52:41.206732Z","iopub.execute_input":"2024-11-29T02:52:41.207001Z","iopub.status.idle":"2024-11-29T02:52:41.243034Z","shell.execute_reply.started":"2024-11-29T02:52:41.206966Z","shell.execute_reply":"2024-11-29T02:52:41.242205Z"}},"outputs":[{"name":"stdout","text":"Phrase (Decoder Inputs): tf.Tensor(\n[[-1.2144066   1.808098    2.1426094  ...  0.42330128  0.61128515\n  -1.8838092 ]\n [-1.5048839   2.035796    1.7815506  ...  0.39550194  0.62154907\n  -1.5194979 ]\n [-1.491255    2.0297668   1.612138   ...  0.42516923  0.6213869\n  -1.3991629 ]\n ...\n [ 0.          0.          0.         ...  0.33687034  0.78608394\n  -1.8386133 ]\n [ 0.          0.          0.         ...  0.37190276  0.7497251\n  -1.9831192 ]\n [ 0.          0.          0.         ...  0.40220946  0.6746319\n  -2.052107  ]], shape=(128, 78), dtype=float32)\nKeypoints (Shape): (32, 128, 78)\nDecoder Outputs: tf.Tensor(\n[60 21 22 24 12 24 20 21 12 22 15 17 20 61 59 59 59 59 59 59 59 59 59 59\n 59 59 59 59 59 59 59 59 59 59 59 59 59 59 59 59 59 59 59 59 59 59 59 59\n 59 59 59 59 59 59 59 59 59 59 59 59 59 59 59 59], shape=(64,), dtype=int32)\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"from tensorflow import keras\nfrom tensorflow.keras import layers\nimport tensorflow as tf\nfrom tensorflow.keras.callbacks import LearningRateScheduler\n\n\nCONV2DLAYER = 256\nDENSELAYER = 128\nENCODER_DIM = 64\nBLOCKS = 2\nDECODER_DIM = 208\nDECODER_DENSE_FFN_DIM = 208\nFEATURE_EXTRACTOR_DIM = 52\nMULTIPLICATION_FACTOR_ENCODER = 4\nNUM_ENCODER_BLOCKS = 2 # Set to either 7 or 14\n\n\nclass LandmarkEmbedding(layers.Layer):\n    def __init__(self, num_hid=200, maxlen=TIME):\n        super().__init__()\n        self.conv1 = tf.keras.layers.Conv1D(\n            num_hid, 11, padding=\"same\", activation=\"relu\"\n        )\n        self.conv2 = tf.keras.layers.Conv1D(\n            num_hid, 11, padding=\"same\", activation=\"relu\"\n        )\n        self.conv3 = tf.keras.layers.Conv1D(\n            num_hid, 11, padding=\"same\", activation=\"relu\"\n        )\n        self.pos_emb = self.positional_encoding(maxlen, num_hid)\n        self.maxlen = maxlen\n        self.num_hid = num_hid\n\n    def call(self, x):\n        x = self.conv1(x)\n        x = self.conv2(x)\n        x = self.conv3(x)\n        \n        x = tf.math.multiply(x, tf.math.sqrt(tf.cast(self.num_hid, tf.float32)))\n        x = x + self.pos_emb\n        \n        return x\n    \n    def positional_encoding(self, maxlen, num_hid):\n        depth = num_hid/2\n        positions = tf.range(maxlen, dtype = tf.float32)[..., tf.newaxis]\n        depths = tf.range(depth, dtype = tf.float32)[np.newaxis, :]/depth\n        angle_rates = tf.math.divide(1, tf.math.pow(tf.cast(10000, tf.float32), depths))\n        angle_rads = tf.linalg.matmul(positions, angle_rates)\n        pos_encoding = tf.concat(\n          [tf.math.sin(angle_rads), tf.math.cos(angle_rads)],\n          axis=-1) \n        return pos_encoding\n\n\nclass PositionalEncoding(layers.Layer):\n    def __init__(self, num_vocab=NUM_CLASSES, maxlen=max_len, num_hid=DECODER_DIM):\n        super().__init__()\n        self.num_hid = num_hid\n        self.emb = tf.keras.layers.Embedding(num_vocab, num_hid)\n        #self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=num_hid)\n        '''\n        self.pos_emb = tf.math.divide(\n            self.positional_encoding(maxlen-1, num_hid),\n            tf.math.sqrt(tf.cast(num_hid, tf.float32)))\n        '''\n        self.pos_emb = self.positional_encoding(maxlen, num_hid)\n\n    def call(self, x):\n        seq_len = tf.shape(x)[1]  # Sequence length of the input\n        x = self.emb(x)  # Shape: [batch_size, seq_len, num_hid]\n        x *= tf.math.sqrt(tf.cast(self.num_hid, tf.float32))  # Scale embeddings\n        \n        # Add positional encoding (broadcast to match input shape)\n        pos_encoding = self.pos_emb[:seq_len, :]  # Shape: [seq_len, num_hid]\n        pos_encoding = tf.expand_dims(pos_encoding, axis=0)  # Shape: [1, seq_len, num_hid]\n        return x + pos_encoding  # Broadcasting happens here\n\n    \n    def positional_encoding(self, maxlen, num_hid):\n        depth = num_hid/2\n        positions = tf.range(maxlen, dtype = tf.float32)[..., tf.newaxis]\n        depths = tf.range(depth, dtype = tf.float32)[np.newaxis, :]/depth\n        angle_rates = tf.math.divide(1, tf.math.pow(tf.cast(10000, tf.float32), depths))\n        angle_rads = tf.linalg.matmul(positions, angle_rates)\n        pos_encoding = tf.concat(\n          [tf.math.sin(angle_rads), tf.math.cos(angle_rads)],\n          axis=-1) \n        return pos_encoding\n# Adapted from github -- This code was NOT written by me\ndef shape_list(x, out_type=tf.int32): # This function is used to easily get the shape of a tensor\n    static = x.shape.as_list()\n    dynamic = tf.shape(x, out_type=out_type)\n    return [dynamic[i] if s is None else s for i, s in enumerate(static)]\n\n# Feed-Forward Network with dropout and swish activation\nclass FFN(tf.keras.layers.Layer):\n    def __init__(self, out, ffmult=4):\n        super(FFN, self).__init__()\n        self.dense1 = layers.Dense(ffmult * out, activation='swish')\n        self.dense2 = layers.Dense(out)\n        self.dropout1 = layers.Dropout(0.1)\n        self.dropout2 = layers.Dropout(0.1)\n    \n    def call(self, inputs, training=True):\n        x = self.dense1(inputs)\n        x = self.dropout1(x, training=training)\n        x = self.dense2(x)\n        x = self.dropout2(x, training=training)\n        return x\n\n# Gated Linear Unit activation, which is more stable than ReLU\nclass FastGLU(tf.keras.layers.Layer):\n    def __init__(self, in_size):\n        super(FastGLU, self).__init__()\n        self.in_size = in_size\n        self.linear = tf.keras.layers.Dense(in_size * 2)  # Linear layer that outputs 2 * in_size \n        # Relu  \n\n    def call(self, X):\n        out = self.linear(X)  # Apply the linear layer\n        # Split the output into two parts\n        linear_part, gate_part = tf.split(out, num_or_size_splits=2, axis=-1)\n        # Add sigmoid\n        gated_output = linear_part * tf.nn.sigmoid(gate_part)\n        return gated_output\n\n# Convolution block, used in the encoder\nclass Conv(tf.keras.layers.Layer):\n\n    def __init__(self, in_size, kernel_size=31, stride=1, exp=2):\n        # We're using a 1x1 convolution to expand the channels, then a 31x1 convolution, then a 1x1 convolution to reduce the channels back to the original size\n        # All with dropout, bn, and GLU activation\n        super(Conv, self).__init__()\n        self.conv1 = tf.keras.layers.Conv2D(exp * in_size, kernel_size=1, strides=stride, padding='valid')\n        self.conv2 = tf.keras.layers.Conv2D(in_size, kernel_size=1, strides=stride, padding='valid')\n        self.bn = tf.keras.layers.BatchNormalization(momentum=0.9, epsilon=1e-5)\n        self.act = tf.keras.layers.Activation(tf.nn.swish)\n        self.glu = FastGLU(in_size=exp * in_size)  \n        self.conv_dw = tf.keras.layers.DepthwiseConv2D(kernel_size=(kernel_size, 1), strides=stride, padding='same', depth_multiplier=1)\n        self.dropout = tf.keras.layers.Dropout(0.1)\n\n    def call(self, x, training=True):\n        B, T, S = shape_list(x)\n        x = tf.reshape(x, (B, T, 1, S))   \n        x = self.conv1(x)  \n        x = self.glu(x)\n        x = self.conv_dw(x)\n        x = self.bn(x)\n        x = self.act(x)  \n        x = self.conv2(x)\n        x = tf.reshape(x, (B, T, S))\n        x = self.dropout(x, training=training)\n        return x  \n\n# LLaMA Attention does not need positional embeddings which have to be calculated for each input, speeding up training time by 250% \n# This allows us to use more parameters\n# This LLaMA is half-adapted half origimal, as the original is in pytorch\nclass LLaMAAttention(tf.keras.layers.Layer):\n    def __init__(self, num_heads, head_dim):\n        super().__init__()\n        self.num_heads = num_heads\n        self.head_dim = head_dim\n        self.scaling = 1 / tf.math.sqrt(tf.cast(head_dim, tf.float32))\n        self.dense_qkv = tf.keras.layers.Dense(3 * self.num_heads * self.head_dim, use_bias=False)\n        self.out_proj = tf.keras.layers.Dense(num_heads * head_dim, use_bias=False)\n    \n    \n    def apply_attention(self, query, key, value):\n        # query, key, value shape: [batch, num_heads, seq_len, head_dim]\n        \n        # Calculate attention scores\n        scores = tf.matmul(query, key, transpose_b=True) * self.scaling  # [batch, num_heads, seq_len, seq_len]\n\n        # Apply softmax\n        attention_weights = tf.nn.softmax(scores, axis=-1)\n        \n        # Apply attention to values\n        output = tf.matmul(attention_weights, value)  # [batch, num_heads, seq_len, head_dim]\n        return output\n    \n    def call(self, inputs, freqs):\n        batch_size, seq_len, _ = tf.unstack(tf.shape(inputs))\n\n        # Compute QK and V\n        qkv = self.dense_qkv(inputs)\n        qkv = tf.reshape(qkv, [batch_size, seq_len, 3, self.num_heads, self.head_dim])\n        query, key, value = tf.unstack(qkv, axis=2)\n        \n        # Reshape freqs to match the shape of query and key\n        freqs = tf.reshape(freqs, [1, seq_len, 1, self.head_dim])\n        freqs = tf.repeat(freqs, repeats=self.num_heads, axis=2)\n        \n        # Apply rotary positional embeddings\n        query = apply_rotary_emb(freqs, query)\n        key = apply_rotary_emb(freqs, key)\n        \n        # Transpose for attention calculation\n        # QKV are all going to be the same here because it is self attention\n        query = tf.transpose(query, [0, 2, 1, 3])  # [batch, num_heads, seq_len, head_dim]\n        key = tf.transpose(key, [0, 2, 1, 3])\n        value = tf.transpose(value, [0, 2, 1, 3])\n \n        # Apply custom attention\n        attn_output = self.apply_attention(\n            query=query,\n            key=key,\n            value=value\n        )\n        \n        # Reshape attention output\n        attn_output = tf.transpose(attn_output, [0, 2, 1, 3])  # [batch, seq_len, num_heads, head_dim]\n        attn_output = tf.reshape(attn_output, [batch_size, seq_len, self.num_heads * self.head_dim])\n        \n        # Project back to how it was\n        output = self.out_proj(attn_output)\n        \n        return output\n\n\n\n# LLaMA Attention uses rotary embeddings, which are more computationally efficient than the standard positional embeddings.\nclass RotaryPositionalEmbedding(tf.keras.layers.Layer):\n    def __init__(self, d_model, max_seq_len):\n        super(RotaryPositionalEmbedding, self).__init__()\n        self.d_model = d_model\n        self.max_seq_len = max_seq_len\n\n    def build(self, _):\n        # Create positional embedding matrix\n        position = tf.range(self.max_seq_len, dtype=tf.float32)[:, tf.newaxis]\n        div_term = tf.exp(tf.range(0, self.d_model, 2, dtype=tf.float32) * -(tf.math.log(10000.0) / self.d_model))\n        pos_encoding = tf.concat([\n            tf.sin(position * div_term),\n            tf.cos(position * div_term)\n        ], axis=-1)\n        self.positional_embedding = tf.Variable(pos_encoding, trainable=False)\n\n    def call(self, x):\n        seq_len = tf.shape(x)[1]\n        return self.positional_embedding[:seq_len, :]\n    \n\n# The SqueezeFormer is better than the original encoder for this case because the conv paired with attention can capture relationships between the \n# long number of frames we are dealing with per sequence\n# It's also computationally quicker\nclass SqueezeformerBlock(tf.keras.layers.Layer):\n    def __init__(self, ff_dim, num_heads, multiplication_factor):\n        super(SqueezeformerBlock, self).__init__()\n        self.ff_dim = ff_dim\n        self.num_heads = num_heads\n        self.multiplication_factor = multiplication_factor\n\n        # LLama \n        self.llama_attention = LLaMAAttention(num_heads=num_heads, head_dim=ff_dim // num_heads)\n\n        # FFN\n        self.ffn1 = FFN(self.ff_dim, self.multiplication_factor)\n        self.ffn2 = FFN(self.ff_dim, self.multiplication_factor)\n\n        # Conv Module\n        self.conv = Conv(ff_dim)\n\n        # Layer Normalizations\n        self.layernorm1 = layers.LayerNormalization(epsilon=1e-5)\n        self.layernorm2 = layers.LayerNormalization(epsilon=1e-5)\n        self.layernorm3 = layers.LayerNormalization(epsilon=1e-5)\n\n    def call(self, inputs, freqs):\n        attn_output = self.llama_attention(inputs, freqs)\n        x = self.layernorm1(inputs + attn_output)\n\n        \n        ff_output = self.ffn1(x)\n        x = self.layernorm2(x + ff_output)  # Residual connection\n\n        conv_output = self.conv(x)\n        x = self.layernorm3(x + conv_output)  # Residual connection\n\n        ff_output = self.ffn2(x)\n        x = self.layernorm3(x + ff_output)  # Residual connection\n        return x\n\n\n\n\nclass EncoderBlock(tf.keras.layers.Layer):\n    def __init__(self, num_blocks=NUM_ENCODER_BLOCKS, num_heads=4, ff_dim=200, ml=TIME):\n        super(EncoderBlock, self).__init__()\n        self.blocks = [SqueezeformerBlock(ff_dim, num_heads, MULTIPLICATION_FACTOR_ENCODER) for _ in range(num_blocks)]\n        self.rope = RotaryPositionalEmbedding(d_model=ff_dim // num_heads, max_seq_len=ml)\n\n    def call(self, inputs):\n        freqs = self.rope(inputs) # Calculate the rotary embeddings once, and we can reuse them for each block as they're all the same length (padded)\n        x = inputs\n        for block in self.blocks:\n            x = block(x, freqs)\n        \n        return x\n\n\nclass BasicEncoder(layers.Layer):\n    def __init__(self, embed_dim=ENCODER_DIM, num_heads=4, feed_forward_dim=400, rate=0.1):\n        super().__init__()\n        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=256)\n        self.ffn = keras.Sequential(\n            [\n                layers.Dense(400, activation=\"relu\"),\n                layers.Dense(200),\n            ]\n        )\n        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n        self.dropout1 = layers.Dropout(rate)\n        self.dropout2 = layers.Dropout(rate)\n\n    def call(self, inputs, training=True):\n        attn_output = self.att(inputs, inputs)\n        attn_output = self.dropout1(attn_output, training=training)\n        out1 = self.layernorm1(inputs + attn_output)\n        ffn_output = self.ffn(out1)\n        ffn_output = self.dropout2(ffn_output, training=training)\n        return self.layernorm2(out1 + ffn_output)\n\ndef get_causal_attention_mask(labels):\n    # Get the shape dynamically using shape_list\n    shape = shape_list(labels)\n    batch_size, seq_length = shape[0], shape[1]\n    \n    # Create a look-ahead mask for a single sequence (shape: [seq_length, seq_length])\n    causal_mask = tf.linalg.band_part(tf.ones((seq_length, seq_length)), -1, 0)\n    \n    # Expand causal mask to (1, seq_length, seq_length) for broadcasting\n    causal_mask = tf.expand_dims(causal_mask, axis=0)\n    \n    # Tile the mask along batch dimension: (batch_size, seq_length, seq_length)\n    causal_mask = tf.tile(causal_mask, [batch_size, 1, 1])\n    \n    return tf.cast(causal_mask, tf.float32)\n\n\nclass Decoder(layers.Layer):\n    def __init__(self, embed_dim=DECODER_DIM, num_heads=8, feed_forward_dim=DECODER_DENSE_FFN_DIM, dropout_rate=0.1):\n        super().__init__()\n        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n        self.layernorm3 = layers.LayerNormalization(epsilon=1e-6)\n        self.self_att = layers.MultiHeadAttention(\n            num_heads=num_heads, key_dim=256\n        )\n        self.enc_att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=200)\n        self.self_dropout = layers.Dropout(0.5)\n        self.enc_dropout = layers.Dropout(0.1)\n        self.ffn_dropout = layers.Dropout(0.1)\n        self.ffn = keras.Sequential(\n            [\n                layers.Dense(400, activation=\"relu\"),\n                layers.Dense(200),\n            ]\n        )\n    def call(self, target, enc_out, mask=None, training=True):\n        input_shape = tf.shape(target)\n        batch_size = input_shape[0]\n        seq_len = input_shape[1]\n        causal_mask = get_causal_attention_mask(target)\n        target_att = self.self_att(target, target, attention_mask=causal_mask)\n        target_norm = self.layernorm1(target + self.self_dropout(target_att, training = training))\n        enc_out = self.enc_att(target_norm, enc_out)\n        enc_out_norm = self.layernorm2(self.enc_dropout(enc_out, training = training) + target_norm)\n        ffn_out = self.ffn(enc_out_norm)\n        ffn_out_norm = self.layernorm3(enc_out_norm + self.ffn_dropout(ffn_out, training = training))\n        return ffn_out_norm\n        \ndef shape_list(x, out_type=tf.int32): # This function is used to easily get the shape of a tensor\n    static = x.shape.as_list()\n    dynamic = tf.shape(x, out_type=out_type)\n    return [dynamic[i] if s is None else s for i, s in enumerate(static)]\n\n\n@tf.keras.utils.register_keras_serializable('model', 'ASLFingerspellingModel')\nclass ASLFingerspellingModel(keras.Model):\n    def __init__(self, num_classes, **kwargs):\n        self.decoder = Decoder()\n        self.le = LandmarkEmbedding()\n        self.enc = keras.Sequential(\n            [self.le]\n            + [\n                EncoderBlock()\n            ]\n        )\n        self.concat = layers.Concatenate(axis=2) \n        self.add = layers.Add()\n        self.dropout = layers.Dropout(0.1)\n        # no softmax? Let's try it...\n        self.output_layer = layers.Dense(NUM_CLASSES, activation=\"softmax\") # This should be NUM_CLASSES?? Even if we're not predicting the SOS token...\n        self.pos_encoding = PositionalEncoding(NUM_CLASSES, max_len - 1, 200)  # These need to be calculated EACH TIME\n        self.num_classes = num_classes\n        super(ASLFingerspellingModel, self).__init__(**kwargs)\n\n\n    def call(self, inputs, training=True):\n        inputs, outputs = inputs[0], inputs[1]\n        DI = outputs[:, :-1]\n        encoded = self.enc(inputs)\n\n        decoded = self.decoder(self.pos_encoding(DI), encoded, mask=None)\n\n        decoded = self.dropout(decoded, training=training)\n        return self.output_layer(decoded)   \n\n    def train_step(self, data):\n        inp, out = data\n        with tf.GradientTape() as tape:\n            preds = self((inp, out), training=True)\n            loss = self.compiled_loss(out[:, 1:], preds, regularization_losses=self.losses)\n        gradients = tape.gradient(loss, self.trainable_variables)\n        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n        self.compiled_metrics.update_state(out[:, 1:], preds)\n        return {m.name: m.result() for m in self.metrics}\n\n    def test_step(self, data):\n        inp, out = data\n        preds = self((inp, out), training=False)\n        loss = self.compiled_loss(out[:, 1:], preds, regularization_losses=self.losses)\n        self.compiled_metrics.update_state(out[:, 1:], preds)\n        return {m.name: m.result() for m in self.metrics}\n    \n\n    def predict(self, x, training=False):\n        # Pass through the encoder\n        enc = self.enc(x, training=training)\n    \n        # Initialize the decoder input with SOS_TOKEN\n        batch_size = tf.shape(x)[0]\n        dec_input = tf.ones((batch_size, 1), dtype=tf.int32) * SOS_TOKEN\n        # Greedy decoding\n        for _ in range(max_len - 1):\n            # Decode using the current input\n            dec_out = self.decoder(self.pos_encoding(dec_input), enc, mask=None, training=training)\n            \n            # Compute logits and predict the next token\n            logits = self.output_layer(dec_out[:, -1:])  # Focus only on the last timestep\n            next_token = tf.argmax(logits, axis=-1, output_type=tf.int32)\n    \n            # Stop if all sequences predict EOS\n            if tf.reduce_all(next_token == EOS_TOKEN):\n                break\n    \n            # Append the predicted token to the decoder input\n            dec_input = tf.concat([dec_input, next_token], axis=-1)\n    \n        # Return the generated sequence without the initial SOS token\n        return dec_input[:, 1:]\n\n\nmodel = ASLFingerspellingModel(NUM_CLASSES)\n# Custom CCE because we want to ignore padding tokens\nclass MaskedSCCE(tf.keras.losses.Loss): \n    def __init__(self, num_classes=NUM_CLASSES, from_logits=False, **kwargs): # from logits = FALSE because our output dense has softmax\n        super().__init__(**kwargs)\n        self.num_classes = num_classes\n        self.from_logits = from_logits\n\n    def call(self, y_true, y_pred):\n        print(y_true, y_pred)\n        # Cast y_true to integer type\n        y_true = tf.cast(y_true, tf.int32)\n        \n        # Create a mask where padding tokens are ignored\n        mask = tf.cast(y_true != PAD_TOKEN, tf.float32)  # Shape: [batch_size, seq_len]\n        # One-hot encode y_true\n        y_true_one_hot = tf.one_hot(y_true, self.num_classes, axis=-1, dtype=tf.float32)  # Shape: [batch_size, seq_len, num_classes]\n        \n        # Calculate categorical cross-entropy loss\n        loss = tf.keras.losses.categorical_crossentropy(y_true_one_hot, y_pred, from_logits=self.from_logits)  # Shape: [batch_size, seq_len]\n        \n        # Apply the mask to ignore padding positions in the loss\n        loss = loss * mask  # Masked loss, Shape: [batch_size, seq_len]\n        \n        valid_tokens = tf.reduce_sum(mask)\n        valid_tokens = tf.maximum(valid_tokens, 1.0)\n        \n        # Calculate the final loss by summing and normalizing over the valid tokens\n        loss = tf.reduce_sum(loss) / valid_tokens\n        \n        return loss\n\n    def get_config(self):\n        # To be able to be saved\n        config = super().get_config()\n        config.update({\n            \"num_classes\": self.num_classes,\n            \"from_logits\": self.from_logits\n        })\n        return config\n\n\nloss = MaskedSCCE()\nadam = keras.optimizers.Adam(learning_rate=1e-4)\n\n\nmodel.compile(\n    optimizer=adam,\n    loss=loss,\n    metrics=['accuracy'])\nEPOCHS = 315\n\n# adapted and modified\ndef lrfn(current_step, num_warmup_steps, lr_max, num_cycles=0.50, num_training_steps=EPOCHS):\n    WARMUP_METHOD = \"exp\"\n    if current_step < num_warmup_steps:\n        if WARMUP_METHOD == 'log':\n            return lr_max * 0.10 ** (num_warmup_steps - current_step)\n        else:\n            return lr_max * 2 ** -(num_warmup_steps - current_step)\n    else:\n        progress = float(current_step - num_warmup_steps) / float(max(1, num_training_steps - num_warmup_steps))\n\n        return max(0.0, 0.5 * (1.0 + math.cos(math.pi * float(num_cycles) * 2.0 * progress))) * lr_max\n\n\nLR_SCHEDULE = [lrfn(step, num_warmup_steps=5, lr_max=1e-3, num_cycles=0.50) for step in range(EPOCHS)]\nlr_callback = tf.keras.callbacks.LearningRateScheduler(lambda step: LR_SCHEDULE[step], verbose=0)\n\nclass printCB(tf.keras.callbacks.Callback):\n    def __init__(self, batch):\n        self.batch = batch\n        inp, out = batch\n        print(out[0:1])\n    def on_epoch_end(self, epoch, logs=None):\n        inputs, outputs = self.batch\n        src = inputs[0:1]\n        tgt = outputs[0:1]\n        tf.print(\"tgt\", tgt)\n        # Autoregressive inference (assuming this method works)\n\n        output_sequence = self.model.predict(src)[0]\n        # Map from token indices back to characters\n        d = {v: k for k, v in char_to_idx.items()}\n        chars = [d[ix.numpy()] for ix in output_sequence if ix.numpy() != EOS_TOKEN]\n        predicted_word = ''.join(chars)\n\n        # Print true labels and predictions\n        print(\"\\nY True: \", \"\".join([d[i.numpy()] for i in tgt[0]]))\n        print(\"Y pred inference: \", predicted_word)\n\n        # Run inference with the current model\n        y_pred_training = self.model((src,tgt), training=False)\n        y_pred_training = tf.argmax(y_pred_training, axis=-1)\n\n        # Flatten the predicted sequence tensor and filter out EOS_TOKEN directly in TensorFlow\n        y_pred_training_flat = tf.reshape(y_pred_training, [-1])  # Flatten the tensor\n        filtered_pred = tf.boolean_mask(y_pred_training_flat, y_pred_training_flat != EOS_TOKEN)  # Remove EOS tokens\n        \n        # Convert indices to characters and join them into the final string\n        predicted_word_training = ''.join([d[ix.numpy()] for ix in filtered_pred])\n        print(\"Y pred training: \", predicted_word_training)\n\n\ncb = printCB(next(iter(val_dataset)))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-29T02:52:41.244628Z","iopub.execute_input":"2024-11-29T02:52:41.244976Z","iopub.status.idle":"2024-11-29T02:52:41.411771Z","shell.execute_reply.started":"2024-11-29T02:52:41.244939Z","shell.execute_reply":"2024-11-29T02:52:41.410912Z"}},"outputs":[{"name":"stdout","text":"tf.Tensor(\n[[60 18  0 34 49 36 36 42 39 46 52 50 36 61 59 59 59 59 59 59 59 59 59 59\n  59 59 59 59 59 59 59 59 59 59 59 59 59 59 59 59 59 59 59 59 59 59 59 59\n  59 59 59 59 59 59 59 59 59 59 59 59 59 59 59 59]], shape=(1, 64), dtype=int32)\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"history = model.fit(train_dataset, epochs=80, validation_data=(val_dataset), verbose=1, callbacks=[cb])\nmodel.save(\"/kaggle/working/model.keras\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-29T02:52:41.412927Z","iopub.execute_input":"2024-11-29T02:52:41.413645Z","iopub.status.idle":"2024-11-29T05:14:53.443702Z","shell.execute_reply.started":"2024-11-29T02:52:41.413596Z","shell.execute_reply":"2024-11-29T05:14:53.442518Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/80\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/layer.py:361: UserWarning: `build()` was called on layer 'asl_fingerspelling_model_3', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Tensor(\"compile_loss/masked_scce_3/Cast:0\", shape=(None, None), dtype=float32) Tensor(\"asl_fingerspelling_model_3_1/dense_67_1/Softmax:0\", shape=(None, None, 62), dtype=float32)\nTensor(\"compile_loss/masked_scce_3/Cast:0\", shape=(None, None), dtype=float32) Tensor(\"asl_fingerspelling_model_3_1/dense_67_1/Softmax:0\", shape=(None, None, 62), dtype=float32)\n\u001b[1m1520/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.0629 - loss: 0.0161Tensor(\"compile_loss/masked_scce_3/Cast:0\", shape=(None, None), dtype=float32) Tensor(\"asl_fingerspelling_model_3_1/dense_67_1/Softmax:0\", shape=(None, None, 62), dtype=float32)\ntgt [[60 18 0 ... 59 59 59]]\n\nY True:  <SOS>3 creekhouse<EOS><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\nY pred inference:  3 cher hores\nY pred training:  3 chenr  rs\n\u001b[1m1520/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 98ms/step - accuracy: 0.0629 - loss: 0.0161 - val_accuracy: 0.1395 - val_loss: 0.0161\nEpoch 2/80\n\u001b[1m1520/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.1513 - loss: 0.0161tgt [[60 18 0 ... 59 59 59]]\n\nY True:  <SOS>3 creekhouse<EOS><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\nY pred inference:  3 crekhorse\nY pred training:  3 crekk orse\n\u001b[1m1520/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 79ms/step - accuracy: 0.1513 - loss: 0.0161 - val_accuracy: 0.1944 - val_loss: 0.0161\nEpoch 3/80\n\u001b[1m1519/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.1932 - loss: 0.0161tgt [[60 18 0 ... 59 59 59]]\n\nY True:  <SOS>3 creekhouse<EOS><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\nY pred inference:  3 crek horse\nY pred training:  3 crekk orse\n\u001b[1m1520/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 78ms/step - accuracy: 0.1932 - loss: 0.0161 - val_accuracy: 0.2076 - val_loss: 0.0161\nEpoch 4/80\n\u001b[1m1519/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.2066 - loss: 0.0161tgt [[60 18 0 ... 59 59 59]]\n\nY True:  <SOS>3 creekhouse<EOS><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\nY pred inference:  3 creek horse\nY pred training:  3 creek orse\n\u001b[1m1520/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 78ms/step - accuracy: 0.2066 - loss: 0.0161 - val_accuracy: 0.2137 - val_loss: 0.0161\nEpoch 5/80\n\u001b[1m1519/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.2142 - loss: 0.0161tgt [[60 18 0 ... 59 59 59]]\n\nY True:  <SOS>3 creekhouse<EOS><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\nY pred inference:  3 creek house\nY pred training:  3 creek ouse\n\u001b[1m1520/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 78ms/step - accuracy: 0.2142 - loss: 0.0161 - val_accuracy: 0.2183 - val_loss: 0.0161\nEpoch 6/80\n\u001b[1m1519/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.2197 - loss: 0.0161tgt [[60 18 0 ... 59 59 59]]\n\nY True:  <SOS>3 creekhouse<EOS><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\nY pred inference:  3 creek horse\nY pred training:  3 creek orse\n\u001b[1m1520/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 78ms/step - accuracy: 0.2197 - loss: 0.0161 - val_accuracy: 0.2210 - val_loss: 0.0161\nEpoch 7/80\n\u001b[1m1519/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.2239 - loss: 0.0161tgt [[60 18 0 ... 59 59 59]]\n\nY True:  <SOS>3 creekhouse<EOS><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\nY pred inference:  3 creek house\nY pred training:  3 creek ouse\n\u001b[1m1520/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 78ms/step - accuracy: 0.2239 - loss: 0.0161 - val_accuracy: 0.2228 - val_loss: 0.0161\nEpoch 8/80\n\u001b[1m1519/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.2272 - loss: 0.0161tgt [[60 18 0 ... 59 59 59]]\n\nY True:  <SOS>3 creekhouse<EOS><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\nY pred inference:  3 creek house\nY pred training:  3 creek ouse\n\u001b[1m1520/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 78ms/step - accuracy: 0.2272 - loss: 0.0161 - val_accuracy: 0.2226 - val_loss: 0.0161\nEpoch 9/80\n\u001b[1m1519/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.2302 - loss: 0.0161tgt [[60 18 0 ... 59 59 59]]\n\nY True:  <SOS>3 creekhouse<EOS><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\nY pred inference:  3 creek house\nY pred training:  3 creek ouse\n\u001b[1m1520/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 78ms/step - accuracy: 0.2302 - loss: 0.0161 - val_accuracy: 0.2236 - val_loss: 0.0161\nEpoch 10/80\n\u001b[1m1519/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.2330 - loss: 0.0161tgt [[60 18 0 ... 59 59 59]]\n\nY True:  <SOS>3 creekhouse<EOS><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\nY pred inference:  3 creek house\nY pred training:  3 creek ouse\n\u001b[1m1520/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 78ms/step - accuracy: 0.2330 - loss: 0.0161 - val_accuracy: 0.2233 - val_loss: 0.0161\nEpoch 11/80\n\u001b[1m1519/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.2353 - loss: 0.0161tgt [[60 18 0 ... 59 59 59]]\n\nY True:  <SOS>3 creekhouse<EOS><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\nY pred inference:  3 creek house\nY pred training:  3 creek ouse\n\u001b[1m1520/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 78ms/step - accuracy: 0.2353 - loss: 0.0161 - val_accuracy: 0.2247 - val_loss: 0.0161\nEpoch 12/80\n\u001b[1m1519/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.2372 - loss: 0.0161tgt [[60 18 0 ... 59 59 59]]\n\nY True:  <SOS>3 creekhouse<EOS><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\nY pred inference:  3 creek house\nY pred training:  3 creek ouse\n\u001b[1m1520/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 78ms/step - accuracy: 0.2372 - loss: 0.0161 - val_accuracy: 0.2240 - val_loss: 0.0161\nEpoch 13/80\n\u001b[1m1520/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.2392 - loss: 0.0161tgt [[60 18 0 ... 59 59 59]]\n\nY True:  <SOS>3 creekhouse<EOS><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\nY pred inference:  3 creek house\nY pred training:  3 creek ouse\n\u001b[1m1520/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 78ms/step - accuracy: 0.2392 - loss: 0.0161 - val_accuracy: 0.2240 - val_loss: 0.0161\nEpoch 14/80\n\u001b[1m1519/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.2409 - loss: 0.0161tgt [[60 18 0 ... 59 59 59]]\n\nY True:  <SOS>3 creekhouse<EOS><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\nY pred inference:  3 creek house\nY pred training:  3 creek ouse\n\u001b[1m1520/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 78ms/step - accuracy: 0.2409 - loss: 0.0161 - val_accuracy: 0.2241 - val_loss: 0.0161\nEpoch 15/80\n\u001b[1m1519/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.2424 - loss: 0.0161tgt [[60 18 0 ... 59 59 59]]\n\nY True:  <SOS>3 creekhouse<EOS><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\nY pred inference:  3 creek house\nY pred training:  3 creek ouse\n\u001b[1m1520/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 78ms/step - accuracy: 0.2424 - loss: 0.0161 - val_accuracy: 0.2246 - val_loss: 0.0161\nEpoch 16/80\n\u001b[1m1519/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.2440 - loss: 0.0161tgt [[60 18 0 ... 59 59 59]]\n\nY True:  <SOS>3 creekhouse<EOS><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\nY pred inference:  3 creek house\nY pred training:  3 creek ouse\n\u001b[1m1520/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 78ms/step - accuracy: 0.2440 - loss: 0.0161 - val_accuracy: 0.2243 - val_loss: 0.0161\nEpoch 17/80\n\u001b[1m1519/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.2454 - loss: 0.0161tgt [[60 18 0 ... 59 59 59]]\n\nY True:  <SOS>3 creekhouse<EOS><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\nY pred inference:  3 creek house\nY pred training:  3 creek ouse\n\u001b[1m1520/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 78ms/step - accuracy: 0.2454 - loss: 0.0161 - val_accuracy: 0.2251 - val_loss: 0.0161\nEpoch 18/80\n\u001b[1m1519/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.2468 - loss: 0.0161tgt [[60 18 0 ... 59 59 59]]\n\nY True:  <SOS>3 creekhouse<EOS><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\nY pred inference:  3 creek house\nY pred training:  3 creek orse\n\u001b[1m1520/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 78ms/step - accuracy: 0.2468 - loss: 0.0161 - val_accuracy: 0.2255 - val_loss: 0.0161\nEpoch 19/80\n\u001b[1m1519/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.2479 - loss: 0.0161tgt [[60 18 0 ... 59 59 59]]\n\nY True:  <SOS>3 creekhouse<EOS><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\nY pred inference:  3 creek house\nY pred training:  3 creek ouse\n\u001b[1m1520/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 78ms/step - accuracy: 0.2479 - loss: 0.0161 - val_accuracy: 0.2242 - val_loss: 0.0161\nEpoch 20/80\n\u001b[1m1519/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.2491 - loss: 0.0161tgt [[60 18 0 ... 59 59 59]]\n\nY True:  <SOS>3 creekhouse<EOS><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\nY pred inference:  3 creek horse\nY pred training:  3 creek orse\n\u001b[1m1520/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 78ms/step - accuracy: 0.2491 - loss: 0.0161 - val_accuracy: 0.2250 - val_loss: 0.0161\nEpoch 21/80\n\u001b[1m1519/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.2506 - loss: 0.0161tgt [[60 18 0 ... 59 59 59]]\n\nY True:  <SOS>3 creekhouse<EOS><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\nY pred inference:  3 creek house\nY pred training:  3 creek ouse\n\u001b[1m1520/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 78ms/step - accuracy: 0.2506 - loss: 0.0161 - val_accuracy: 0.2246 - val_loss: 0.0161\nEpoch 22/80\n\u001b[1m1519/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.2517 - loss: 0.0161tgt [[60 18 0 ... 59 59 59]]\n\nY True:  <SOS>3 creekhouse<EOS><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\nY pred inference:  3 creek horse\nY pred training:  3 creek orse\n\u001b[1m1520/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 78ms/step - accuracy: 0.2517 - loss: 0.0161 - val_accuracy: 0.2232 - val_loss: 0.0161\nEpoch 23/80\n\u001b[1m1519/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.2525 - loss: 0.0161tgt [[60 18 0 ... 59 59 59]]\n\nY True:  <SOS>3 creekhouse<EOS><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\nY pred inference:  3 creek horse\nY pred training:  3 creek orse\n\u001b[1m1520/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 78ms/step - accuracy: 0.2525 - loss: 0.0161 - val_accuracy: 0.2236 - val_loss: 0.0161\nEpoch 24/80\n\u001b[1m1519/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.2538 - loss: 0.0161tgt [[60 18 0 ... 59 59 59]]\n\nY True:  <SOS>3 creekhouse<EOS><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\nY pred inference:  3 creek horse\nY pred training:  3 creek orse\n\u001b[1m1520/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 78ms/step - accuracy: 0.2538 - loss: 0.0161 - val_accuracy: 0.2232 - val_loss: 0.0161\nEpoch 25/80\n\u001b[1m1519/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.2547 - loss: 0.0161tgt [[60 18 0 ... 59 59 59]]\n\nY True:  <SOS>3 creekhouse<EOS><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\nY pred inference:  3 creek horse\nY pred training:  3 creek orse\n\u001b[1m1520/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 78ms/step - accuracy: 0.2547 - loss: 0.0161 - val_accuracy: 0.2234 - val_loss: 0.0161\nEpoch 26/80\n\u001b[1m1519/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.2556 - loss: 0.0161tgt [[60 18 0 ... 59 59 59]]\n\nY True:  <SOS>3 creekhouse<EOS><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\nY pred inference:  3 crekhorse\nY pred training:  3 crekk orse\n\u001b[1m1520/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 78ms/step - accuracy: 0.2556 - loss: 0.0161 - val_accuracy: 0.2240 - val_loss: 0.0161\nEpoch 27/80\n\u001b[1m1519/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.2564 - loss: 0.0161tgt [[60 18 0 ... 59 59 59]]\n\nY True:  <SOS>3 creekhouse<EOS><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\nY pred inference:  3 creek horse\nY pred training:  3 creek orse\n\u001b[1m1520/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 78ms/step - accuracy: 0.2564 - loss: 0.0161 - val_accuracy: 0.2234 - val_loss: 0.0161\nEpoch 28/80\n\u001b[1m1519/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.2573 - loss: 0.0161tgt [[60 18 0 ... 59 59 59]]\n\nY True:  <SOS>3 creekhouse<EOS><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\nY pred inference:  3 crek horse\nY pred training:  3 crekk orse\n\u001b[1m1520/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 78ms/step - accuracy: 0.2573 - loss: 0.0161 - val_accuracy: 0.2239 - val_loss: 0.0161\nEpoch 29/80\n\u001b[1m1519/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.2585 - loss: 0.0161tgt [[60 18 0 ... 59 59 59]]\n\nY True:  <SOS>3 creekhouse<EOS><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\nY pred inference:  3 crek horse\nY pred training:  3 crekk orse\n\u001b[1m1520/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 78ms/step - accuracy: 0.2585 - loss: 0.0161 - val_accuracy: 0.2237 - val_loss: 0.0161\nEpoch 30/80\n\u001b[1m1519/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.2592 - loss: 0.0161tgt [[60 18 0 ... 59 59 59]]\n\nY True:  <SOS>3 creekhouse<EOS><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\nY pred inference:  3 creek house\nY pred training:  3 creek ouse\n\u001b[1m1520/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 78ms/step - accuracy: 0.2592 - loss: 0.0161 - val_accuracy: 0.2237 - val_loss: 0.0161\nEpoch 31/80\n\u001b[1m1519/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.2603 - loss: 0.0161tgt [[60 18 0 ... 59 59 59]]\n\nY True:  <SOS>3 creekhouse<EOS><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\nY pred inference:  3 creek horse\nY pred training:  3 creek orse\n\u001b[1m1520/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 78ms/step - accuracy: 0.2603 - loss: 0.0161 - val_accuracy: 0.2235 - val_loss: 0.0161\nEpoch 32/80\n\u001b[1m1519/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.2609 - loss: 0.0161tgt [[60 18 0 ... 59 59 59]]\n\nY True:  <SOS>3 creekhouse<EOS><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\nY pred inference:  3 creek horse\nY pred training:  3 creek orse\n\u001b[1m1520/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 78ms/step - accuracy: 0.2609 - loss: 0.0161 - val_accuracy: 0.2235 - val_loss: 0.0161\nEpoch 33/80\n\u001b[1m1519/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.2619 - loss: 0.0161tgt [[60 18 0 ... 59 59 59]]\n\nY True:  <SOS>3 creekhouse<EOS><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\nY pred inference:  3 creek horse\nY pred training:  3 creek orse\n\u001b[1m1520/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 78ms/step - accuracy: 0.2619 - loss: 0.0161 - val_accuracy: 0.2230 - val_loss: 0.0161\nEpoch 34/80\n\u001b[1m1519/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.2626 - loss: 0.0161tgt [[60 18 0 ... 59 59 59]]\n\nY True:  <SOS>3 creekhouse<EOS><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\nY pred inference:  3 creekhouse\nY pred training:  3 creekhouse\n\u001b[1m1520/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 78ms/step - accuracy: 0.2626 - loss: 0.0161 - val_accuracy: 0.2230 - val_loss: 0.0161\nEpoch 35/80\n\u001b[1m1519/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.2633 - loss: 0.0161tgt [[60 18 0 ... 59 59 59]]\n\nY True:  <SOS>3 creekhouse<EOS><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\nY pred inference:  33 creekhorse\nY pred training:  33creekhorse\n\u001b[1m1520/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 78ms/step - accuracy: 0.2633 - loss: 0.0161 - val_accuracy: 0.2235 - val_loss: 0.0161\nEpoch 36/80\n\u001b[1m1519/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.2641 - loss: 0.0161tgt [[60 18 0 ... 59 59 59]]\n\nY True:  <SOS>3 creekhouse<EOS><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\nY pred inference:  33 creek house\nY pred training:  33creek orse\n\u001b[1m1520/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 78ms/step - accuracy: 0.2641 - loss: 0.0161 - val_accuracy: 0.2238 - val_loss: 0.0161\nEpoch 37/80\n\u001b[1m1519/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.2649 - loss: 0.0161tgt [[60 18 0 ... 59 59 59]]\n\nY True:  <SOS>3 creekhouse<EOS><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\nY pred inference:  3 creek horse\nY pred training:  3 creek orse\n\u001b[1m1520/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 78ms/step - accuracy: 0.2649 - loss: 0.0161 - val_accuracy: 0.2233 - val_loss: 0.0161\nEpoch 38/80\n\u001b[1m1519/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.2655 - loss: 0.0161tgt [[60 18 0 ... 59 59 59]]\n\nY True:  <SOS>3 creekhouse<EOS><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\nY pred inference:  3 creekhouse\nY pred training:  3 creekhouse\n\u001b[1m1520/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 78ms/step - accuracy: 0.2655 - loss: 0.0161 - val_accuracy: 0.2229 - val_loss: 0.0161\nEpoch 39/80\n\u001b[1m1519/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.2662 - loss: 0.0161tgt [[60 18 0 ... 59 59 59]]\n\nY True:  <SOS>3 creekhouse<EOS><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\nY pred inference:  3 creekhorse\nY pred training:  3 creekhorse\n\u001b[1m1520/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 78ms/step - accuracy: 0.2662 - loss: 0.0161 - val_accuracy: 0.2233 - val_loss: 0.0161\nEpoch 40/80\n\u001b[1m1519/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.2668 - loss: 0.0161tgt [[60 18 0 ... 59 59 59]]\n\nY True:  <SOS>3 creekhouse<EOS><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\nY pred inference:  3 creekhouse\nY pred training:  3 creekhouse\n\u001b[1m1520/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 78ms/step - accuracy: 0.2668 - loss: 0.0161 - val_accuracy: 0.2233 - val_loss: 0.0161\nEpoch 41/80\n\u001b[1m1519/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.2675 - loss: 0.0161tgt [[60 18 0 ... 59 59 59]]\n\nY True:  <SOS>3 creekhouse<EOS><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\nY pred inference:  33 creekhouse\nY pred training:  33creek ouse\n\u001b[1m1520/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 78ms/step - accuracy: 0.2675 - loss: 0.0161 - val_accuracy: 0.2220 - val_loss: 0.0161\nEpoch 42/80\n\u001b[1m1519/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.2681 - loss: 0.0161tgt [[60 18 0 ... 59 59 59]]\n\nY True:  <SOS>3 creekhouse<EOS><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\nY pred inference:  3 crekhorse\nY pred training:  3 crekk orse\n\u001b[1m1520/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 78ms/step - accuracy: 0.2681 - loss: 0.0161 - val_accuracy: 0.2229 - val_loss: 0.0161\nEpoch 43/80\n\u001b[1m1519/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.2689 - loss: 0.0161tgt [[60 18 0 ... 59 59 59]]\n\nY True:  <SOS>3 creekhouse<EOS><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\nY pred inference:  3 creek horse\nY pred training:  3 creek orse\n\u001b[1m1520/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 78ms/step - accuracy: 0.2689 - loss: 0.0161 - val_accuracy: 0.2236 - val_loss: 0.0161\nEpoch 44/80\n\u001b[1m1519/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.2693 - loss: 0.0161tgt [[60 18 0 ... 59 59 59]]\n\nY True:  <SOS>3 creekhouse<EOS><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\nY pred inference:  3 creekhouse\nY pred training:  3 creekhouse\n\u001b[1m1520/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 78ms/step - accuracy: 0.2693 - loss: 0.0161 - val_accuracy: 0.2232 - val_loss: 0.0161\nEpoch 45/80\n\u001b[1m1519/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.2699 - loss: 0.0161tgt [[60 18 0 ... 59 59 59]]\n\nY True:  <SOS>3 creekhouse<EOS><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\nY pred inference:  3 crekhouse\nY pred training:  3 crekk ouse\n\u001b[1m1520/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 78ms/step - accuracy: 0.2699 - loss: 0.0161 - val_accuracy: 0.2232 - val_loss: 0.0161\nEpoch 46/80\n\u001b[1m1519/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.2704 - loss: 0.0161tgt [[60 18 0 ... 59 59 59]]\n\nY True:  <SOS>3 creekhouse<EOS><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\nY pred inference:  3 creek horse\nY pred training:  3 creek orse\n\u001b[1m1520/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 78ms/step - accuracy: 0.2704 - loss: 0.0161 - val_accuracy: 0.2231 - val_loss: 0.0161\nEpoch 47/80\n\u001b[1m1519/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.2709 - loss: 0.0161tgt [[60 18 0 ... 59 59 59]]\n\nY True:  <SOS>3 creekhouse<EOS><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\nY pred inference:  3 creekhouse\nY pred training:  3 creekhouse\n\u001b[1m1520/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 78ms/step - accuracy: 0.2709 - loss: 0.0161 - val_accuracy: 0.2229 - val_loss: 0.0161\nEpoch 48/80\n\u001b[1m1519/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.2716 - loss: 0.0161tgt [[60 18 0 ... 59 59 59]]\n\nY True:  <SOS>3 creekhouse<EOS><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\nY pred inference:  3 creek house\nY pred training:  3 creek ouse\n\u001b[1m1520/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 78ms/step - accuracy: 0.2716 - loss: 0.0161 - val_accuracy: 0.2231 - val_loss: 0.0161\nEpoch 49/80\n\u001b[1m1519/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.2717 - loss: 0.0161tgt [[60 18 0 ... 59 59 59]]\n\nY True:  <SOS>3 creekhouse<EOS><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\nY pred inference:  3 creekhouse\nY pred training:  3 creekhouse\n\u001b[1m1520/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 78ms/step - accuracy: 0.2717 - loss: 0.0161 - val_accuracy: 0.2233 - val_loss: 0.0161\nEpoch 50/80\n\u001b[1m1519/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.2726 - loss: 0.0161tgt [[60 18 0 ... 59 59 59]]\n\nY True:  <SOS>3 creekhouse<EOS><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\nY pred inference:  3 creekhouse\nY pred training:  3 creekhouse\n\u001b[1m1520/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 78ms/step - accuracy: 0.2726 - loss: 0.0161 - val_accuracy: 0.2231 - val_loss: 0.0161\nEpoch 51/80\n\u001b[1m1519/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.2728 - loss: 0.0161tgt [[60 18 0 ... 59 59 59]]\n\nY True:  <SOS>3 creekhouse<EOS><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\nY pred inference:  3 creekhouse\nY pred training:  3 creekhouse\n\u001b[1m1520/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 78ms/step - accuracy: 0.2728 - loss: 0.0161 - val_accuracy: 0.2229 - val_loss: 0.0161\nEpoch 52/80\n\u001b[1m1519/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.2734 - loss: 0.0161tgt [[60 18 0 ... 59 59 59]]\n\nY True:  <SOS>3 creekhouse<EOS><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\nY pred inference:  3 creek house\nY pred training:  3 creek ouse\n\u001b[1m1520/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 78ms/step - accuracy: 0.2734 - loss: 0.0161 - val_accuracy: 0.2234 - val_loss: 0.0161\nEpoch 53/80\n\u001b[1m1519/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.2739 - loss: 0.0161tgt [[60 18 0 ... 59 59 59]]\n\nY True:  <SOS>3 creekhouse<EOS><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\nY pred inference:  3 creek house\nY pred training:  3 creek ouse\n\u001b[1m1520/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 78ms/step - accuracy: 0.2739 - loss: 0.0161 - val_accuracy: 0.2233 - val_loss: 0.0161\nEpoch 54/80\n\u001b[1m1519/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.2742 - loss: 0.0161tgt [[60 18 0 ... 59 59 59]]\n\nY True:  <SOS>3 creekhouse<EOS><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\nY pred inference:  33 creek house\nY pred training:  33creek ouse\n\u001b[1m1520/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 78ms/step - accuracy: 0.2742 - loss: 0.0161 - val_accuracy: 0.2231 - val_loss: 0.0161\nEpoch 55/80\n\u001b[1m1519/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.2748 - loss: 0.0161tgt [[60 18 0 ... 59 59 59]]\n\nY True:  <SOS>3 creekhouse<EOS><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\nY pred inference:  33 creek house\nY pred training:  33creek ouse\n\u001b[1m1520/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 78ms/step - accuracy: 0.2748 - loss: 0.0161 - val_accuracy: 0.2227 - val_loss: 0.0161\nEpoch 56/80\n\u001b[1m1519/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.2751 - loss: 0.0161tgt [[60 18 0 ... 59 59 59]]\n\nY True:  <SOS>3 creekhouse<EOS><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\nY pred inference:  33 creek house\nY pred training:  33creek ouse\n\u001b[1m1520/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 78ms/step - accuracy: 0.2751 - loss: 0.0161 - val_accuracy: 0.2229 - val_loss: 0.0161\nEpoch 57/80\n\u001b[1m1519/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.2754 - loss: 0.0161tgt [[60 18 0 ... 59 59 59]]\n\nY True:  <SOS>3 creekhouse<EOS><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\nY pred inference:  33 creekhouse\nY pred training:  33creekhouse\n\u001b[1m1520/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 78ms/step - accuracy: 0.2754 - loss: 0.0161 - val_accuracy: 0.2232 - val_loss: 0.0161\nEpoch 58/80\n\u001b[1m1519/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.2757 - loss: 0.0161tgt [[60 18 0 ... 59 59 59]]\n\nY True:  <SOS>3 creekhouse<EOS><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\nY pred inference:  33 creek house\nY pred training:  33creek ouse\n\u001b[1m1520/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 78ms/step - accuracy: 0.2757 - loss: 0.0161 - val_accuracy: 0.2226 - val_loss: 0.0161\nEpoch 59/80\n\u001b[1m1519/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.2761 - loss: 0.0161tgt [[60 18 0 ... 59 59 59]]\n\nY True:  <SOS>3 creekhouse<EOS><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\nY pred inference:  3 creek house\nY pred training:  3 creek ouse\n\u001b[1m1520/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 78ms/step - accuracy: 0.2761 - loss: 0.0161 - val_accuracy: 0.2230 - val_loss: 0.0161\nEpoch 60/80\n\u001b[1m1519/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.2764 - loss: 0.0161tgt [[60 18 0 ... 59 59 59]]\n\nY True:  <SOS>3 creekhouse<EOS><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\nY pred inference:  3 creekhouse\nY pred training:  3 creekhouse\n\u001b[1m1520/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 78ms/step - accuracy: 0.2764 - loss: 0.0161 - val_accuracy: 0.2237 - val_loss: 0.0161\nEpoch 61/80\n\u001b[1m1519/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.2769 - loss: 0.0161tgt [[60 18 0 ... 59 59 59]]\n\nY True:  <SOS>3 creekhouse<EOS><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\nY pred inference:  3 creekhouse\nY pred training:  3 creekhouse\n\u001b[1m1520/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 78ms/step - accuracy: 0.2769 - loss: 0.0161 - val_accuracy: 0.2224 - val_loss: 0.0161\nEpoch 62/80\n\u001b[1m1519/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.2773 - loss: 0.0161tgt [[60 18 0 ... 59 59 59]]\n\nY True:  <SOS>3 creekhouse<EOS><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\nY pred inference:  3 creek house\nY pred training:  3 creek ouse\n\u001b[1m1520/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 78ms/step - accuracy: 0.2773 - loss: 0.0161 - val_accuracy: 0.2234 - val_loss: 0.0161\nEpoch 63/80\n\u001b[1m1519/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.2773 - loss: 0.0161tgt [[60 18 0 ... 59 59 59]]\n\nY True:  <SOS>3 creekhouse<EOS><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\nY pred inference:  3 creek house\nY pred training:  3 creek ouse\n\u001b[1m1520/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 78ms/step - accuracy: 0.2773 - loss: 0.0161 - val_accuracy: 0.2233 - val_loss: 0.0161\nEpoch 64/80\n\u001b[1m1519/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.2777 - loss: 0.0161tgt [[60 18 0 ... 59 59 59]]\n\nY True:  <SOS>3 creekhouse<EOS><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\nY pred inference:  3 creekhouse\nY pred training:  3 creekhouse\n\u001b[1m1520/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 78ms/step - accuracy: 0.2777 - loss: 0.0161 - val_accuracy: 0.2238 - val_loss: 0.0161\nEpoch 65/80\n\u001b[1m1519/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.2781 - loss: 0.0161tgt [[60 18 0 ... 59 59 59]]\n\nY True:  <SOS>3 creekhouse<EOS><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\nY pred inference:  3 creek house\nY pred training:  3 creek ouse\n\u001b[1m1520/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 78ms/step - accuracy: 0.2782 - loss: 0.0161 - val_accuracy: 0.2226 - val_loss: 0.0161\nEpoch 66/80\n\u001b[1m1519/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.2782 - loss: 0.0161tgt [[60 18 0 ... 59 59 59]]\n\nY True:  <SOS>3 creekhouse<EOS><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\nY pred inference:  33 creek house\nY pred training:  33creek ouse\n\u001b[1m1520/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 78ms/step - accuracy: 0.2782 - loss: 0.0161 - val_accuracy: 0.2239 - val_loss: 0.0161\nEpoch 67/80\n\u001b[1m1519/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.2787 - loss: 0.0161tgt [[60 18 0 ... 59 59 59]]\n\nY True:  <SOS>3 creekhouse<EOS><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\nY pred inference:  33 creek house\nY pred training:  33creek orse\n\u001b[1m1520/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 78ms/step - accuracy: 0.2787 - loss: 0.0161 - val_accuracy: 0.2241 - val_loss: 0.0161\nEpoch 68/80\n\u001b[1m1519/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.2791 - loss: 0.0161tgt [[60 18 0 ... 59 59 59]]\n\nY True:  <SOS>3 creekhouse<EOS><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\nY pred inference:  3 creekhorse\nY pred training:  3 creekhorse\n\u001b[1m1520/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 78ms/step - accuracy: 0.2791 - loss: 0.0161 - val_accuracy: 0.2228 - val_loss: 0.0161\nEpoch 69/80\n\u001b[1m1519/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.2791 - loss: 0.0161tgt [[60 18 0 ... 59 59 59]]\n\nY True:  <SOS>3 creekhouse<EOS><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\nY pred inference:  33 creekhorse\nY pred training:  33creekhorse\n\u001b[1m1520/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 78ms/step - accuracy: 0.2791 - loss: 0.0161 - val_accuracy: 0.2229 - val_loss: 0.0161\nEpoch 70/80\n\u001b[1m1519/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.2794 - loss: 0.0161tgt [[60 18 0 ... 59 59 59]]\n\nY True:  <SOS>3 creekhouse<EOS><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\nY pred inference:  33 creek house\nY pred training:  33creek ouse\n\u001b[1m1520/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 78ms/step - accuracy: 0.2794 - loss: 0.0161 - val_accuracy: 0.2228 - val_loss: 0.0161\nEpoch 71/80\n\u001b[1m1519/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.2797 - loss: 0.0161tgt [[60 18 0 ... 59 59 59]]\n\nY True:  <SOS>3 creekhouse<EOS><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\nY pred inference:  33 creek house\nY pred training:  33creek ouse\n\u001b[1m1520/1520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 78ms/step - accuracy: 0.2797 - loss: 0.0161 - val_accuracy: 0.2236 - val_loss: 0.0161\nEpoch 72/80\n\u001b[1m 331/1520\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:31\u001b[0m 77ms/step - accuracy: 0.2784 - loss: 0.0161","output_type":"stream"},{"name":"stderr","text":"\nKeyboardInterrupt\n\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"model.save(\"/kaggle/working/model.keras\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-29T05:15:13.451288Z","iopub.execute_input":"2024-11-29T05:15:13.452216Z","iopub.status.idle":"2024-11-29T05:15:13.894374Z","shell.execute_reply.started":"2024-11-29T05:15:13.452178Z","shell.execute_reply":"2024-11-29T05:15:13.893632Z"}},"outputs":[],"execution_count":28}]}